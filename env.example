# =============================================================================
# Kafka 配置
# =============================================================================
# Kafka 集群地址
KAFKA_BOOTSTRAP_SERVERS=localhost:9092

# Kafka 主题名称
KAFKA_TOPIC_TASKS=obs-file-tasks

# Kafka 消费组 ID
KAFKA_GROUP_ID=obs-worker-group

# Kafka 安全协议 (PLAINTEXT, SASL_PLAINTEXT, SASL_SSL, SSL)
KAFKA_SECURITY_PROTOCOL=PLAINTEXT

# SASL 认证机制 (PLAIN, SCRAM-SHA-256, SCRAM-SHA-512)
KAFKA_SASL_MECHANISM=PLAIN

# SASL 用户名
KAFKA_SASL_USERNAME=

# SASL 密码
KAFKA_SASL_PASSWORD=

# =============================================================================
# OBS 对象存储配置
# =============================================================================
# OBS 访问密钥
OBS_ACCESS_KEY=your_access_key_here

# OBS 密钥
OBS_SECRET_KEY=your_secret_key_here

# OBS 服务器地址
OBS_SERVER=https://obs.cn-north-4.myhuaweicloud.com

# OBS 区域代号
OBS_REGION=cn-north-4

# 源桶名称（下载文件的桶）
OBS_SOURCE_BUCKET=source-bucket

# 目标桶名称（上传解析结果的桶）
OBS_DEST_BUCKET=dest-bucket

# 本地下载目录
OBS_DOWNLOAD_DIR=./work/downloads

# 本地输出目录
OBS_UPLOAD_DIR=./work/outputs

# =============================================================================
# Worker 配置
# =============================================================================
# 进程池大小（仅用于 obs_kafka_pool_worker.py）
POOL_SIZE=4

# DBC 解析器工厂函数路径（格式：module_path:factory_symbol）
# 例如：my_dbc_parser:create_parser
DBC_FACTORY=

# 文件清理配置
CLEANUP_FILES=true
CLEANUP_ON_ERROR=false

# =============================================================================
# 任务生成器配置
# =============================================================================
# 任务生成模式（single/batch）
TASK_MODE=batch

# 单个文件模式配置
SINGLE_FILE=

# 批量模式配置
SOURCE_BUCKET=
FILE_PREFIX=
DEST_BUCKET=
MAX_FILES=1000

# Kafka 生产者配置
KAFKA_RESULT_TOPIC=file-processing-results
KAFKA_ENABLE_PRODUCER=true

# =============================================================================
# Chroma + Ollama 配置（用于 ingest.py 和 search.py）
# =============================================================================
# Ollama 服务地址
OLLAMA_HOST=http://localhost:11434

# Ollama 模型名称
OLLAMA_MODEL=llama2

# Chroma 数据库路径
CHROMA_DB_PATH=./chroma_db

# Chroma 集合名称
CHROMA_COLLECTION_NAME=documents

# =============================================================================
# ingest.py 配置
# =============================================================================
# 数据目录（包含 JSON 文件）
DATA_DIR=./data

# Chroma 数据库目录
CHROMA_DB_DIR=./chroma_db

# Chroma 集合名称
CHROMA_COLLECTION=docs

# Ollama 嵌入模型名称
OLLAMA_EMBED_MODEL=nomic-embed-text

# Ollama 基础 URL
OLLAMA_BASE_URL=http://localhost:11434

# 批量插入大小
BATCH_SIZE=128

# =============================================================================
# search.py 配置
# =============================================================================
# 搜索查询文本（必需）
SEARCH_QUERY=your search query here

# 返回结果数量
SEARCH_K=5

# =============================================================================
# 使用说明
# =============================================================================
# 1. 复制此文件为 .env
#    cp env.example .env
#
# 2. 编辑 .env 文件，填入你的实际配置值
#
# 3. 启动 Worker：
#    简单 Worker: python obs_kafka_worker.py
#    多进程 Worker: python obs_kafka_pool_worker.py
#
# 4. 启动向量化脚本：
#    数据摄入: python ingest.py
#    向量搜索: python search.py
#
# 注意：search.py 需要设置 SEARCH_QUERY 环境变量
