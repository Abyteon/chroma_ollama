# ğŸ“š Kafkaæ–‡ä»¶å¤„ç†å®Œæ•´æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®æä¾›åŸºäºKafkaçš„åˆ†å¸ƒå¼æ–‡ä»¶å¤„ç†è§£å†³æ–¹æ¡ˆï¼Œä¸“é—¨ç”¨äºå¤„ç†å­˜å‚¨åœ¨åä¸ºäº‘OBSä¸­çš„æ–‡ä»¶ã€‚ç³»ç»ŸåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œå½¢æˆå®Œæ•´çš„å¤„ç†é“¾è·¯ï¼š

```
ä»»åŠ¡ç”Ÿæˆå™¨ â†’ Kafkaé˜Ÿåˆ— â†’ Workerå¤„ç†å™¨ â†’ ç»“æœé€šçŸ¥
    â†“           â†“          â†“           â†“
  æ‰«æOBS    å¤„ç†ä»»åŠ¡    æ–‡ä»¶å¤„ç†    çŠ¶æ€åé¦ˆ
```

### ğŸ¯ æ ¸å¿ƒç»„ä»¶

1. **ğŸ”„ ä»»åŠ¡ç”Ÿæˆå™¨** (`task_generator`) - æ‰«æOBSæ–‡ä»¶å¹¶ç”Ÿæˆå¤„ç†ä»»åŠ¡
2. **âš™ï¸ å•è¿›ç¨‹Worker** (`worker`) - é€‚åˆè½»é‡çº§æ–‡ä»¶å¤„ç†
3. **ğŸš€ å¤šè¿›ç¨‹Worker** (`pool_worker`) - é€‚åˆå¤§æ–‡ä»¶å’Œé«˜å¹¶å‘å¤„ç†

### ğŸŒŸ ç³»ç»Ÿç‰¹ç‚¹

- **åˆ†å¸ƒå¼å¤„ç†** - æ”¯æŒå¤šWorkerå®ä¾‹å¹¶è¡Œå¤„ç†
- **å®¹é”™æ€§å¼º** - è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯æ¢å¤æœºåˆ¶
- **èµ„æºä¼˜åŒ–** - æ™ºèƒ½æ–‡ä»¶æ¸…ç†å’Œå†…å­˜ç®¡ç†
- **å®æ—¶ç›‘æ§** - å®Œæ•´çš„å¤„ç†çŠ¶æ€è¿½è¸ª
- **é«˜å¯æ‰©å±•** - æ°´å¹³æ‰©å±•æ”¯æŒæ›´é«˜ååé‡

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

#### å®‰è£…ä¾èµ–
```bash
# ä½¿ç”¨pixiï¼ˆæ¨èï¼‰
pixi install

# æˆ–ä½¿ç”¨pip
pip install -e .
```

#### é…ç½®ç¯å¢ƒ
å¤åˆ¶å¹¶ç¼–è¾‘ç¯å¢ƒé…ç½®ï¼š
```bash
cp env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥å®é™…é…ç½®
```

### 2. åŸºç¡€é…ç½®

#### æœ€å°é…ç½®ç¤ºä¾‹ï¼ˆ.envæ–‡ä»¶ï¼‰
```bash
# ===== Kafkaé…ç½® =====
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_TASKS=file-processing-tasks
KAFKA_RESULT_TOPIC=file-processing-results
KAFKA_GROUP_ID=obs-workers

# ===== OBSé…ç½® =====
OBS_ACCESS_KEY=your_access_key
OBS_SECRET_KEY=your_secret_key
OBS_SERVER=https://obs.cn-north-4.myhuaweicloud.com
OBS_REGION=cn-north-4
OBS_SOURCE_BUCKET=input-files
OBS_DEST_BUCKET=processed-files

# ===== Workeré…ç½® =====
POOL_SIZE=4
CLEANUP_FILES=true
CLEANUP_ON_ERROR=false
```

### 3. ä¸€é”®å¯åŠ¨

```bash
# ç»ˆç«¯1: ç”Ÿæˆå¤„ç†ä»»åŠ¡
SOURCE_BUCKET=my-bucket FILE_PREFIX=data/ pixi run generate-tasks

# ç»ˆç«¯2: å¯åŠ¨Workerå¤„ç†
pixi run worker

# ç»ˆç«¯3: ç›‘æ§å¤„ç†ç»“æœï¼ˆå¯é€‰ï¼‰
kafka-console-consumer --bootstrap-server localhost:9092 --topic file-processing-results
```

## ğŸ“¤ ä»»åŠ¡ç”Ÿæˆå™¨è¯¦è§£

### åŠŸèƒ½è¯´æ˜
ä»»åŠ¡ç”Ÿæˆå™¨è´Ÿè´£æ‰«æOBSå­˜å‚¨æ¡¶ï¼Œå‘ç°éœ€è¦å¤„ç†çš„æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„Kafkaå¤„ç†ä»»åŠ¡ã€‚

### ä½¿ç”¨æ–¹å¼

#### 1. æ‰¹é‡ä»»åŠ¡ç”Ÿæˆ
```bash
# æ‰«ææ•´ä¸ªæ¡¶
SOURCE_BUCKET=my-bucket pixi run generate-tasks

# æŒ‰å‰ç¼€è¿‡æ»¤ï¼ˆæ¨èï¼‰
SOURCE_BUCKET=my-bucket FILE_PREFIX=data/2024/08/ pixi run generate-tasks

# é™åˆ¶æ–‡ä»¶æ•°é‡
SOURCE_BUCKET=my-bucket MAX_FILES=500 pixi run generate-tasks

# æŒ‡å®šç›®æ ‡æ¡¶
SOURCE_BUCKET=input-bucket DEST_BUCKET=output-bucket pixi run generate-tasks
```

#### 2. å•ä¸ªæ–‡ä»¶ä»»åŠ¡
```bash
# å¤„ç†ç‰¹å®šæ–‡ä»¶
SINGLE_FILE=urgent/data.csv SOURCE_BUCKET=my-bucket pixi run generate-single-task

# æŒ‡å®šè¾“å‡ºè·¯å¾„
SINGLE_FILE=data.txt DEST_BUCKET=results DEST_KEY=processed/data.json pixi run generate-single-task
```

#### 3. é¢„é…ç½®ä»»åŠ¡
```bash
# ä½¿ç”¨é¢„è®¾çš„æ‰¹é‡ä»»åŠ¡é…ç½®
pixi run generate-batch-tasks
```

### ç”Ÿæˆçš„ä»»åŠ¡æ¶ˆæ¯æ ¼å¼

```json
{
  "key": "data/input.csv",                    // å¿…éœ€ï¼šæ–‡ä»¶è·¯å¾„
  "bucket": "source-bucket",                  // å¯é€‰ï¼šæºæ¡¶å
  "dest_bucket": "processed-bucket",          // å¯é€‰ï¼šç›®æ ‡æ¡¶å
  "dest_key": "processed/input.csv.json",    // å¯é€‰ï¼šç›®æ ‡è·¯å¾„
  "size": 1024,                              // æ–‡ä»¶å¤§å°
  "last_modified": "2025-08-25T12:00:00Z",   // ä¿®æ”¹æ—¶é—´
  "generated_at": "2025-08-25T12:05:00Z"     // ç”Ÿæˆæ—¶é—´
}
```

### é«˜çº§åŠŸèƒ½

#### ç¼–ç¨‹å¼ä»»åŠ¡ç”Ÿæˆ
```python
from chroma_ollama.task_generator import TaskGenerator

generator = TaskGenerator()

# ä»æ–‡ä»¶åˆ—è¡¨ç”Ÿæˆä»»åŠ¡
files = ["data/file1.csv", "data/file2.json"]
tasks = generator.generate_task_from_file_list(files, bucket="my-bucket")

# å‘é€åˆ°Kafka
generator.send_tasks_to_kafka(tasks, batch_size=50)

generator.close()
```

## âš™ï¸ Workerå¤„ç†å™¨è¯¦è§£

### å¤„ç†æµç¨‹

æ¯ä¸ªWorkerçš„æ ‡å‡†å¤„ç†æµç¨‹ï¼š

```
1. æ¶ˆè´¹Kafkaä»»åŠ¡æ¶ˆæ¯
   â†“
2. ä»OBSä¸‹è½½æºæ–‡ä»¶åˆ°æœ¬åœ°
   â†“
3. æ‰§è¡Œæ–‡ä»¶è§£æ/å¤„ç†é€»è¾‘
   â†“
4. ä¸Šä¼ å¤„ç†ç»“æœåˆ°ç›®æ ‡OBSæ¡¶
   â†“
5. å‘é€å¤„ç†ç»“æœé€šçŸ¥åˆ°Kafka
   â†“
6. æ¸…ç†æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
   â†“
7. æäº¤Kafkaæ¶ˆæ¯åç§»é‡
```

### å•è¿›ç¨‹Worker

#### é€‚ç”¨åœºæ™¯
- æ–‡ä»¶è¾ƒå°ï¼ˆ< 10MBï¼‰
- å¤„ç†é€»è¾‘ç®€å•
- èµ„æºå—é™ç¯å¢ƒ
- è°ƒè¯•å’Œå¼€å‘é˜¶æ®µ

#### å¯åŠ¨æ–¹å¼
```bash
# åŸºç¡€å¯åŠ¨
pixi run worker

# è‡ªå®šä¹‰é…ç½®å¯åŠ¨
CLEANUP_FILES=false KAFKA_GROUP_ID=debug-group pixi run worker
```

#### ç‰¹ç‚¹
- **è½»é‡çº§** - å†…å­˜å ç”¨å°
- **ç®€å•ç¨³å®š** - å•çº¿ç¨‹å¤„ç†ï¼Œæ˜“äºè°ƒè¯•
- **é€‚åˆå°æ–‡ä»¶** - å¤„ç†é€Ÿåº¦é€‚ä¸­

### å¤šè¿›ç¨‹Worker

#### é€‚ç”¨åœºæ™¯
- å¤§æ–‡ä»¶å¤„ç†ï¼ˆ> 10MBï¼‰
- å¤æ‚çš„æ•°æ®è½¬æ¢
- é«˜ååé‡éœ€æ±‚
- ç”Ÿäº§ç¯å¢ƒ

#### å¯åŠ¨æ–¹å¼
```bash
# åŸºç¡€å¯åŠ¨ï¼ˆ4ä¸ªè¿›ç¨‹ï¼‰
pixi run pool-worker

# è‡ªå®šä¹‰è¿›ç¨‹æ•°
POOL_SIZE=8 pixi run pool-worker

# é«˜æ€§èƒ½é…ç½®
POOL_SIZE=16 CLEANUP_FILES=true pixi run pool-worker
```

#### ç‰¹ç‚¹
- **é«˜æ€§èƒ½** - å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†
- **å¯æ‰©å±•** - æ”¯æŒåŠ¨æ€è°ƒæ•´è¿›ç¨‹æ•°
- **é€‚åˆå¤§æ–‡ä»¶** - æœ‰æ•ˆåˆ©ç”¨å¤šæ ¸CPU

### Workeré…ç½®ä¼˜åŒ–

#### æ€§èƒ½è°ƒä¼˜
```bash
# é«˜ååé‡é…ç½®
POOL_SIZE=16                      # å¢åŠ è¿›ç¨‹æ•°
KAFKA_MAX_POLL_RECORDS=1000       # æ‰¹é‡æ¶ˆè´¹æ¶ˆæ¯
CLEANUP_FILES=true                # åŠæ—¶æ¸…ç†æ–‡ä»¶
KAFKA_SESSION_TIMEOUT_MS=30000    # è°ƒæ•´ä¼šè¯è¶…æ—¶
```

#### è°ƒè¯•é…ç½®
```bash
# è°ƒè¯•æ¨¡å¼
CLEANUP_FILES=false               # ä¿ç•™æ–‡ä»¶ä¾¿äºæ£€æŸ¥
CLEANUP_ON_ERROR=false           # å¤±è´¥æ—¶ä¸æ¸…ç†
KAFKA_AUTO_OFFSET_RESET=earliest # é‡æ–°å¤„ç†æ‰€æœ‰æ¶ˆæ¯
```

#### å®¹é”™é…ç½®
```bash
# é«˜å¯é æ€§é…ç½®
KAFKA_ENABLE_AUTO_COMMIT=false   # æ‰‹åŠ¨æäº¤åç§»é‡
CLEANUP_ON_ERROR=true            # å¤±è´¥æ—¶æ¸…ç†æ–‡ä»¶
KAFKA_MAX_POLL_INTERVAL_MS=600000 # å¢åŠ å¤„ç†è¶…æ—¶
```

## ğŸ“Š ç»“æœé€šçŸ¥ç³»ç»Ÿ

### é€šçŸ¥æœºåˆ¶
æ¯ä¸ªæ–‡ä»¶å¤„ç†å®Œæˆåï¼ŒWorkerä¼šå‘é€è¯¦ç»†çš„ç»“æœé€šçŸ¥åˆ°ä¸“é—¨çš„Kafka Topicã€‚

### æˆåŠŸé€šçŸ¥æ ¼å¼
```json
{
  "timestamp": "2025-08-25T12:30:00Z",
  "worker_type": "single_process",          // Workerç±»å‹
  "status": "success",                      // å¤„ç†çŠ¶æ€
  "source": {
    "bucket": "input-bucket",
    "key": "data/input.csv"
  },
  "destination": {
    "bucket": "output-bucket",
    "key": "data/input.csv.parsed.json"
  },
  "file_info": {
    "input_size": 1024,                     // è¾“å…¥æ–‡ä»¶å¤§å°
    "output_size": 2048,                    // è¾“å‡ºæ–‡ä»¶å¤§å°
    "input_size_formatted": "1.0 KB",      // æ ¼å¼åŒ–å¤§å°
    "output_size_formatted": "2.0 KB"
  }
}
```

### å¤±è´¥é€šçŸ¥æ ¼å¼
```json
{
  "timestamp": "2025-08-25T12:30:00Z",
  "worker_type": "multi_process",
  "status": "failed",
  "source": {
    "bucket": "input-bucket",
    "key": "data/corrupted.csv"
  },
  "error": "æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ",               // é”™è¯¯ä¿¡æ¯
  "file_info": {
    "input_size": 512,
    "output_size": 0
  }
}
```

### ç›‘æ§ç»“æœ
```bash
# å®æ—¶ç›‘æ§æ‰€æœ‰ç»“æœ
kafka-console-consumer --bootstrap-server localhost:9092 --topic file-processing-results

# è¿‡æ»¤æˆåŠŸçš„å¤„ç†
kafka-console-consumer --bootstrap-server localhost:9092 --topic file-processing-results | grep "success"

# è¿‡æ»¤å¤±è´¥çš„å¤„ç†
kafka-console-consumer --bootstrap-server localhost:9092 --topic file-processing-results | grep "failed"
```

## ğŸ”§ å®Œæ•´é…ç½®å‚è€ƒ

### ç¯å¢ƒå˜é‡å®Œæ•´åˆ—è¡¨

#### Kafkaé…ç½®
```bash
# åŸºç¡€è¿æ¥
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_TASKS=file-processing-tasks        # ä»»åŠ¡é˜Ÿåˆ—Topic
KAFKA_RESULT_TOPIC=file-processing-results     # ç»“æœé€šçŸ¥Topic
KAFKA_GROUP_ID=obs-workers                     # æ¶ˆè´¹ç»„ID

# æ¶ˆè´¹è€…é…ç½®
KAFKA_AUTO_OFFSET_RESET=latest                 # earliest|latest
KAFKA_ENABLE_AUTO_COMMIT=true                  # è‡ªåŠ¨æäº¤åç§»é‡
KAFKA_AUTO_COMMIT_INTERVAL_MS=5000            # æäº¤é—´éš”
KAFKA_SESSION_TIMEOUT_MS=10000                # ä¼šè¯è¶…æ—¶
KAFKA_HEARTBEAT_INTERVAL_MS=3000              # å¿ƒè·³é—´éš”
KAFKA_MAX_POLL_INTERVAL_MS=300000             # æœ€å¤§è½®è¯¢é—´éš”
KAFKA_MAX_POLL_RECORDS=500                    # æ¯æ¬¡è½®è¯¢æœ€å¤§è®°å½•æ•°

# ç”Ÿäº§è€…é…ç½®
KAFKA_ENABLE_PRODUCER=true                     # å¯ç”¨ç»“æœé€šçŸ¥

# å®‰å…¨é…ç½®ï¼ˆå¯é€‰ï¼‰
KAFKA_SECURITY_PROTOCOL=PLAINTEXT             # PLAINTEXT|SASL_PLAINTEXT|SASL_SSL|SSL
KAFKA_SASL_MECHANISM=PLAIN                    # PLAIN|SCRAM-SHA-256|SCRAM-SHA-512
KAFKA_SASL_USERNAME=your_username
KAFKA_SASL_PASSWORD=your_password
```

#### OBSé…ç½®
```bash
# è¿æ¥ä¿¡æ¯
OBS_ACCESS_KEY=your_access_key
OBS_SECRET_KEY=your_secret_key
OBS_SERVER=https://obs.cn-north-4.myhuaweicloud.com
OBS_REGION=cn-north-4

# å­˜å‚¨æ¡¶
OBS_SOURCE_BUCKET=input-files                  # æºæ–‡ä»¶æ¡¶
OBS_DEST_BUCKET=processed-files               # ç»“æœæ–‡ä»¶æ¡¶

# æœ¬åœ°è·¯å¾„
OBS_DOWNLOAD_DIR=./work/downloads              # ä¸‹è½½ç›®å½•
OBS_UPLOAD_DIR=./work/uploads                  # ä¸Šä¼ ç›®å½•
```

#### Workeré…ç½®
```bash
# è¿›ç¨‹æ§åˆ¶
POOL_SIZE=4                                   # å¤šè¿›ç¨‹Workerçš„è¿›ç¨‹æ•°

# æ–‡ä»¶ç®¡ç†
CLEANUP_FILES=true                            # å¤„ç†æˆåŠŸåæ¸…ç†æ–‡ä»¶
CLEANUP_ON_ERROR=false                       # å¤„ç†å¤±è´¥åæ¸…ç†æ–‡ä»¶

# è‡ªå®šä¹‰è§£æå™¨ï¼ˆé«˜çº§ï¼‰
DBC_FACTORY=my_module:create_parser           # DBCè§£æå™¨å·¥å‚
```

#### ä»»åŠ¡ç”Ÿæˆå™¨é…ç½®
```bash
# æ‰«æé…ç½®
SOURCE_BUCKET=input-files                     # è¦æ‰«æçš„æ¡¶
FILE_PREFIX=data/2024/08/                    # æ–‡ä»¶å‰ç¼€è¿‡æ»¤
DEST_BUCKET=processed-files                  # ç›®æ ‡æ¡¶ï¼ˆå¯é€‰ï¼‰
MAX_FILES=1000                               # æœ€å¤§æ–‡ä»¶æ•°

# å•æ–‡ä»¶æ¨¡å¼
SINGLE_FILE=specific/file.txt                # å•ä¸ªæ–‡ä»¶è·¯å¾„
```

## ğŸ› ï¸ è¿ç»´å’Œç›‘æ§

### æ—¥å¿—ç›‘æ§

#### ç»“æ„åŒ–æ—¥å¿—æ ¼å¼
Workerè¾“å‡ºJSONæ ¼å¼çš„ç»“æ„åŒ–æ—¥å¿—ï¼š

```json
{
  "timestamp": "2025-08-25T12:00:00Z",
  "level": "info",
  "event": "å¤„ç†å®Œæˆ",
  "filename": "worker.py",
  "func_name": "_process_message", 
  "lineno": 185,
  "file_key": "data/input.csv",
  "processing_time": 2.5,
  "input_size": 1024,
  "output_size": 2048
}
```

#### æ—¥å¿—æŸ¥çœ‹æŠ€å·§
```bash
# å®æ—¶æŸ¥çœ‹Workeræ—¥å¿—
pixi run worker | jq '.'

# è¿‡æ»¤ç‰¹å®šäº‹ä»¶
pixi run worker | jq 'select(.event == "å¤„ç†å®Œæˆ")'

# ç»Ÿè®¡å¤„ç†æ—¶é—´
pixi run worker | jq 'select(.processing_time) | .processing_time'
```

### æ€§èƒ½ç›‘æ§

#### å…³é”®æŒ‡æ ‡
- **å¤„ç†ååé‡** - æ¯åˆ†é’Ÿå¤„ç†æ–‡ä»¶æ•°
- **å¹³å‡å¤„ç†æ—¶é—´** - å•ä¸ªæ–‡ä»¶å¤„ç†è€—æ—¶
- **æˆåŠŸç‡** - å¤„ç†æˆåŠŸçš„æ¯”ä¾‹
- **é”™è¯¯åˆ†å¸ƒ** - å„ç±»é”™è¯¯çš„é¢‘ç‡
- **èµ„æºä½¿ç”¨** - CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨æƒ…å†µ

#### ç›‘æ§è„šæœ¬ç¤ºä¾‹
```bash
#!/bin/bash
# ç®€å•çš„æ€§èƒ½ç›‘æ§è„šæœ¬

# ç»Ÿè®¡æœ€è¿‘1å°æ—¶çš„å¤„ç†ç»“æœ
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic file-processing-results \
  --from-beginning | \
  jq -r 'select(.timestamp > "'$(date -d '1 hour ago' -Iseconds)'") | .status' | \
  sort | uniq -c
```

### æ•…éšœæ’é™¤

#### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

1. **ä»»åŠ¡ç”Ÿæˆå¤±è´¥**
   ```bash
   # ç—‡çŠ¶ï¼šæ‰«æOBSå¤±è´¥
   # æ£€æŸ¥ï¼šOBSè¿æ¥å’Œæƒé™
   # è§£å†³ï¼šéªŒè¯ACCESS_KEYå’ŒSECRET_KEYï¼Œç¡®è®¤æ¡¶æƒé™
   ```

2. **Workeræ— æ³•æ¶ˆè´¹æ¶ˆæ¯**
   ```bash
   # ç—‡çŠ¶ï¼šWorkerå¯åŠ¨ä½†ä¸å¤„ç†æ–‡ä»¶
   # æ£€æŸ¥ï¼šKafkaè¿æ¥å’ŒTopicæ˜¯å¦å­˜åœ¨
   # è§£å†³ï¼šç¡®è®¤BOOTSTRAP_SERVERSï¼Œåˆ›å»ºTopic
   kafka-topics --bootstrap-server localhost:9092 --create --topic file-processing-tasks
   ```

3. **æ–‡ä»¶å¤„ç†å¤±è´¥ç‡é«˜**
   ```bash
   # ç—‡çŠ¶ï¼šå¤§é‡å¤„ç†å¤±è´¥é€šçŸ¥
   # æ£€æŸ¥ï¼šæ–‡ä»¶æ ¼å¼å’Œå¤„ç†é€»è¾‘
   # è§£å†³ï¼šä¿ç•™å¤±è´¥æ–‡ä»¶è¿›è¡Œåˆ†æ
   CLEANUP_ON_ERROR=false pixi run worker
   ```

4. **ç£ç›˜ç©ºé—´ä¸è¶³**
   ```bash
   # ç—‡çŠ¶ï¼šä¸‹è½½å¤±è´¥æˆ–ç³»ç»ŸæŠ¥é”™
   # æ£€æŸ¥ï¼šä¸´æ—¶ç›®å½•ç©ºé—´ä½¿ç”¨
   # è§£å†³ï¼šå¯ç”¨è‡ªåŠ¨æ¸…ç†
   CLEANUP_FILES=true CLEANUP_ON_ERROR=true pixi run worker
   ```

5. **å¤„ç†æ€§èƒ½ä½**
   ```bash
   # ç—‡çŠ¶ï¼šååé‡ä¸æ»¡è¶³éœ€æ±‚
   # æ£€æŸ¥ï¼šè¿›ç¨‹æ•°å’Œç³»ç»Ÿèµ„æº
   # è§£å†³ï¼šå¢åŠ è¿›ç¨‹æ•°æˆ–éƒ¨ç½²å¤šä¸ªWorkerå®ä¾‹
   POOL_SIZE=16 pixi run pool-worker
   ```

## ğŸ“ˆ æ‰©å±•å’Œä¼˜åŒ–

### æ°´å¹³æ‰©å±•

#### éƒ¨ç½²å¤šä¸ªWorkerå®ä¾‹
```bash
# æœºå™¨1
KAFKA_GROUP_ID=workers-group-1 pixi run pool-worker

# æœºå™¨2  
KAFKA_GROUP_ID=workers-group-1 pixi run pool-worker

# æœºå™¨3
KAFKA_GROUP_ID=workers-group-1 pixi run pool-worker
```

#### æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„å¤„ç†
```bash
# CSVæ–‡ä»¶å¤„ç†ç»„
KAFKA_GROUP_ID=csv-processors KAFKA_TOPIC_TASKS=csv-processing-tasks pixi run worker

# JSONæ–‡ä»¶å¤„ç†ç»„
KAFKA_GROUP_ID=json-processors KAFKA_TOPIC_TASKS=json-processing-tasks pixi run worker

# æ—¥å¿—æ–‡ä»¶å¤„ç†ç»„
KAFKA_GROUP_ID=log-processors KAFKA_TOPIC_TASKS=log-processing-tasks pixi run worker
```

### è‡ªå®šä¹‰å¤„ç†é€»è¾‘

#### æ‰©å±•æ–‡ä»¶è§£æå™¨
```python
# åˆ›å»ºè‡ªå®šä¹‰è§£æå™¨ custom_parser.py
from pathlib import Path
import json

def parse_csv_file(input_path: Path, output_path: Path) -> None:
    """è‡ªå®šä¹‰CSVè§£æé€»è¾‘"""
    import pandas as pd
    
    # è¯»å–CSV
    df = pd.read_csv(input_path)
    
    # æ‰§è¡Œè‡ªå®šä¹‰å¤„ç†
    result = {
        "total_rows": len(df),
        "columns": list(df.columns),
        "summary": df.describe().to_dict()
    }
    
    # å†™å…¥ç»“æœ
    output_path.write_text(json.dumps(result, ensure_ascii=False, indent=2))

# åœ¨Workerä¸­ä½¿ç”¨
# ä¿®æ”¹ worker.py çš„ _parse_file æ–¹æ³•è°ƒç”¨ parse_csv_file
```

### é›†æˆå…¶ä»–æœåŠ¡

#### æ•°æ®åº“è®°å½•å¤„ç†çŠ¶æ€
```python
# åœ¨å¤„ç†å®Œæˆåè®°å½•åˆ°æ•°æ®åº“
def record_processing_result(file_key: str, status: str, error: str = None):
    import sqlite3
    
    conn = sqlite3.connect('processing_log.db')
    cursor = conn.cursor()
    
    cursor.execute('''
        INSERT INTO processing_log (file_key, status, error, timestamp)
        VALUES (?, ?, ?, datetime('now'))
    ''', (file_key, status, error))
    
    conn.commit()
    conn.close()
```

#### é‚®ä»¶é€šçŸ¥é›†æˆ
```python
# å¤„ç†å¤±è´¥æ—¶å‘é€é‚®ä»¶é€šçŸ¥
def send_failure_notification(file_key: str, error: str):
    import smtplib
    from email.mime.text import MIMEText
    
    msg = MIMEText(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {file_key}\né”™è¯¯: {error}")
    msg['Subject'] = 'æ–‡ä»¶å¤„ç†å¤±è´¥é€šçŸ¥'
    msg['From'] = 'system@company.com'
    msg['To'] = 'admin@company.com'
    
    # å‘é€é‚®ä»¶é€»è¾‘...
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ä»»åŠ¡è§„åˆ’
- **æŒ‰æ—¶é—´åˆ†æ‰¹å¤„ç†** - é¿å…ä¸€æ¬¡æ€§ç”Ÿæˆè¿‡å¤šä»»åŠ¡
- **åˆç†è®¾ç½®å‰ç¼€** - ä½¿ç”¨æœ‰æ„ä¹‰çš„ç›®å½•ç»“æ„
- **ç›‘æ§é˜Ÿåˆ—é•¿åº¦** - é˜²æ­¢ä»»åŠ¡ç§¯å‹

### 2. èµ„æºç®¡ç†
- **åˆç†é…ç½®è¿›ç¨‹æ•°** - æ ¹æ®CPUæ ¸å¿ƒæ•°å’Œå†…å­˜å®¹é‡
- **å¯ç”¨æ–‡ä»¶æ¸…ç†** - é˜²æ­¢ç£ç›˜ç©ºé—´è€—å°½
- **ç›‘æ§ç³»ç»Ÿèµ„æº** - CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œä½¿ç”¨æƒ…å†µ

### 3. é”™è¯¯å¤„ç†
- **ä¿ç•™å¤±è´¥æ–‡ä»¶** - ä¾¿äºé—®é¢˜è¯Šæ–­å’Œæ•°æ®æ¢å¤
- **å»ºç«‹é‡è¯•æœºåˆ¶** - å¯¹ä¸´æ—¶å¤±è´¥è¿›è¡Œè‡ªåŠ¨é‡è¯•
- **ç›‘æ§é”™è¯¯ç‡** - åŠæ—¶å‘ç°ç³»ç»Ÿé—®é¢˜

### 4. è¿ç»´ç›‘æ§
- **ç»“æ„åŒ–æ—¥å¿—** - ä¾¿äºæ—¥å¿—åˆ†æå’Œé—®é¢˜å®šä½
- **æ€§èƒ½æŒ‡æ ‡æ”¶é›†** - å»ºç«‹å¤„ç†æ€§èƒ½åŸºçº¿
- **å‘Šè­¦æœºåˆ¶** - å¼‚å¸¸æƒ…å†µåŠæ—¶é€šçŸ¥

### 5. å®‰å…¨è€ƒè™‘
- **å¯†é’¥ç®¡ç†** - å®‰å…¨å­˜å‚¨OBSå’ŒKafkaå‡­è¯
- **ç½‘ç»œå®‰å…¨** - ä½¿ç”¨SSL/TLSåŠ å¯†ä¼ è¾“
- **è®¿é—®æ§åˆ¶** - æœ€å°æƒé™åŸåˆ™

è¿™ä¸ªå®Œæ•´çš„Kafkaæ–‡ä»¶å¤„ç†ç³»ç»Ÿä¸ºå¤§è§„æ¨¡ã€åˆ†å¸ƒå¼çš„æ–‡ä»¶å¤„ç†æä¾›äº†å¼ºå¤§è€Œçµæ´»çš„è§£å†³æ–¹æ¡ˆï¼ğŸš€
